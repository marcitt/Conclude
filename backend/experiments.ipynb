{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96eefbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from langchain_community.llms import Ollama \n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e84bd",
   "metadata": {},
   "source": [
    "# Local LLMs with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce615063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**LLM is functioning properly!**\n",
      "\n",
      "**Pytesseract has been successfully set up and is ready for use!**\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3:8b\", temperature=0) \n",
    "\n",
    "print(llm.invoke(\"Please let the user know whether the LLM is working\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f24eb2",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f43c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "pytesseract is working!\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"test.png\")\n",
    "\n",
    "# Run OCR\n",
    "extracted_text = pytesseract.image_to_string(img)\n",
    "\n",
    "# Print the result\n",
    "print(\"Extracted Text:\")\n",
    "print(extracted_text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98961cba",
   "metadata": {},
   "source": [
    "# Generating Fake Banking Data for Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb1c339",
   "metadata": {},
   "source": [
    "# Network Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf7e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b25a02b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_node('Register Death', label='Register Death', priority=3, effort=1, duration=1)\n",
    "G.add_node('Use Tell Us Once', label='Use Tell Us Once', priority=5, effort=1, duration=0.5)\n",
    "G.add_node('Search for Will', label='Search for Will', priority=4, effort=2, duration=2)\n",
    "G.add_node('Choose Funeral Director', label='Choose Funeral Director', priority=2, effort=1, duration=1)\n",
    "G.add_node('Confirm Funeral Arrangements', label='Confirm Funeral Arrangements', priority=2, effort=2, duration=2)\n",
    "G.add_node('Complete Probate Application', label='Complete Probate Application', priority=2, effort=4, duration=5)\n",
    "G.add_node('Verify Executors', label='Verify Executors', priority=2, effort=3, duration=2)\n",
    "G.add_node('Pay Probate', label='Pay Probate', priority=2, effort=1, duration=1)\n",
    "G.add_node('Wait for Grant of Probate', label='Wait for Grant of Probate', priority=2, effort=0.5, duration=20)\n",
    "\n",
    "G.add_edge('Register Death', 'Use Tell Us Once')\n",
    "G.add_edge('Register Death', 'Search for Will')\n",
    "G.add_edge('Search for Will', 'Verify Executors')\n",
    "G.add_edge('Verify Executors', 'Complete Probate Application')\n",
    "G.add_edge('Complete Probate Application', 'Pay Probate')\n",
    "G.add_edge('Pay Probate', 'Wait for Grant of Probate')\n",
    "G.add_edge('Register Death', 'Choose Funeral Director')\n",
    "G.add_edge('Choose Funeral Director', 'Confirm Funeral Arrangements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93bf1c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Ranked Tasks:\n",
      "Use Tell Us Once â€” Score: 10.67\n",
      "Search for Will â€” Score: 9.11\n",
      "Register Death â€” Score: 6.67\n",
      "Pay Probate â€” Score: 5.38\n",
      "Verify Executors â€” Score: 5.36\n",
      "Complete Probate Application â€” Score: 5.29\n",
      "Wait for Grant of Probate â€” Score: 5.0\n",
      "Choose Funeral Director â€” Score: 4.85\n",
      "Confirm Funeral Arrangements â€” Score: 4.4\n"
     ]
    }
   ],
   "source": [
    "centrality = nx.betweenness_centrality(G)\n",
    "task_scores = {}\n",
    "\n",
    "for node in G.nodes:\n",
    "    data = G.nodes[node]\n",
    "    priority = data['priority']\n",
    "    effort = data['effort']\n",
    "    central = centrality.get(node, 0)\n",
    "\n",
    "    # Composite scoring formula\n",
    "    score = (priority * 2.0) + (1 / (effort + 0.5)) + (central * 10)\n",
    "    task_scores[node] = round(score, 2)\n",
    "\n",
    "# Sort by score\n",
    "ranked_tasks = sorted(task_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display\n",
    "print(\"ðŸ“Œ Ranked Tasks:\")\n",
    "for task, score in ranked_tasks:\n",
    "    print(f\"{G.nodes[task]['label']} â€” Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09427e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_tasks = list(nx.topological_sort(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_by_score_and_order = sorted(\n",
    "    ordered_tasks, \n",
    "    key=lambda x: task_scores.get(x, 0), \n",
    "    reverse=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conclude",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
